{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../../')\n",
    "import wandb\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import tempfile\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_CACHE = str(pathlib.PosixPath('~/.wandb_cache').expanduser())\n",
    "VERSION     =\"v0\" ##<- update if you want to use a different verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = os.path.join(WANDB_CACHE,\"aaac_raw:%s\" % VERSION)\n",
    "def grab_raw_data(path):\n",
    "    if not os.path.isdir(FILE_PATH):\n",
    "        with wandb.init() as run: \n",
    "            artifact = run.use_artifact(\n",
    "                'aaac/aaac_model_runs/aaac_raw:%s' % VERSION, \n",
    "                type='dataset'\n",
    "            )\n",
    "            artifact_dir = artifact.download(root=FILE_PATH)\n",
    "grab_raw_data(FILE_PATH) \n",
    "DATA_JSON=os.path.join(FILE_PATH,\"aaac.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grabs the raw `aaac` corpus (with version `v0`) from wandb and places it into a wandb cache. It first requires having some global access to your `WANDB_API_KEY`, which can be set by doing `export WANDB_API_KEY=....` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = []\n",
    "with open(DATA_JSON) as my_data: \n",
    "    for line in my_data: \n",
    "        line      = line.strip()\n",
    "        json_line = json.loads(line)\n",
    "        LINES.append(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LINES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'If, and only if, Keith is a expert of FC Vaduz and Keith is a member of FC Spartak Trnava, then Keith is a critic of FK Jablonec',\n",
       "  'starts_at': 0,\n",
       "  'ref_reco': 1},\n",
       " {'text': 'Keith is not a expert of PSV Eindhoven or Keith is a critic of OGC Nice',\n",
       "  'starts_at': 350,\n",
       "  'ref_reco': 6},\n",
       " {'text': 'if it is not the case that Keith is a expert of FC Vaduz and Keith is a member of FC Spartak Trnava, then Keith is not a critic of OGC Nice',\n",
       "  'starts_at': 430,\n",
       "  'ref_reco': 7},\n",
       " {'text': 'if Keith is a friend of RC Celta de Vigo, then Keith is a expert of PSV Eindhoven',\n",
       "  'starts_at': 575,\n",
       "  'ref_reco': 4},\n",
       " {'text': 'if it is not the case that Keith is a expert of FC Vaduz and Keith is a member of FC Spartak Trnava, then Keith is not a critic of OGC Nice',\n",
       "  'starts_at': 662,\n",
       "  'ref_reco': 7}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LINES[1][\"reason_statements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argument_source',\n",
       " 'argdown_reconstruction',\n",
       " 'reason_statements',\n",
       " 'conclusion_statements',\n",
       " 'explicit_premises',\n",
       " 'explicit_premises_formalized',\n",
       " 'implicit_premises',\n",
       " 'implicit_premises_formalized',\n",
       " 'conclusion',\n",
       " 'conclusion_formalized',\n",
       " 'intermediary_conclusions_formalized',\n",
       " 'intermediary_conclusions',\n",
       " 'id',\n",
       " 'predicate_placeholders',\n",
       " 'entity_placeholders',\n",
       " 'steps',\n",
       " 'n_premises',\n",
       " 'base_scheme_groups',\n",
       " 'scheme_variants',\n",
       " 'domain_id',\n",
       " 'domain_type',\n",
       " 'plcd_subs',\n",
       " 'argdown_index_map',\n",
       " 'presentation_parameters']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(LINES[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amount = int(len(LINES)*0.7)\n",
    "eval_amount  = int(len(LINES)*0.15)\n",
    "random.shuffle(LINES)\n",
    "train_instances = LINES[:train_amount]\n",
    "dev_instances   = LINES[train_amount:train_amount+eval_amount]\n",
    "test_instances  = LINES[train_amount+eval_amount:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just took a random train/test/dev split to start with. Not sure how much this makes sense given the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myakazimir\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dataset_upload</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/aaac/dataset_versions\" target=\"_blank\">https://wandb.ai/aaac/dataset_versions</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/aaac/dataset_versions/runs/5mcwwjso\" target=\"_blank\">https://wandb.ai/aaac/dataset_versions/runs/5mcwwjso</a><br/>\n",
       "                Run data is saved locally in <code>/Users/kyler/projects/transformer_tools/notebooks/wandb/run-20210310_190714-5mcwwjso</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/var/folders/7n/4mvmm_g56gv48s7g5lfzfs880000gp/T/tmpxjtnrdbu)... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19697<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 15.22MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=4.9752029368â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/kyler/projects/transformer_tools/notebooks/wandb/run-20210310_190714-5mcwwjso/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/kyler/projects/transformer_tools/notebooks/wandb/run-20210310_190714-5mcwwjso/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dataset_upload</strong>: <a href=\"https://wandb.ai/aaac/dataset_versions/runs/5mcwwjso\" target=\"_blank\">https://wandb.ai/aaac/dataset_versions/runs/5mcwwjso</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##open wandb again\n",
    "run = wandb.init(entity=\"aaac\",project=\"dataset_versions\",name=\"dataset_upload\")\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tempdir: \n",
    "    for sname,split in [\n",
    "        (\"train\",train_instances),\n",
    "        (\"dev\",dev_instances),\n",
    "        (\"test\",test_instances)\n",
    "    ]:\n",
    "        ### outputfile \n",
    "        over = 0\n",
    "        total = 0\n",
    "        \n",
    "        file_out = os.path.join(tempdir,sname+\".jsonl\")\n",
    "        write_file = open(file_out,'w')\n",
    "    \n",
    "        for k,instance in enumerate(split):\n",
    "            arg_source            = instance[\"argument_source\"]\n",
    "            conclusion_statements = instance[\"conclusion_statements\"]\n",
    "            reason_statements     = instance[\"reason_statements\"]\n",
    "            argdown               = instance[\"argdown_reconstruction\"]\n",
    "        \n",
    "            ### arbitrary limitation on input size for now\n",
    "            ## transformer is limited here\n",
    "            if len(argdown.split()) >= 280: continue \n",
    " \n",
    "        \n",
    "            ### json line format and schema for my model \n",
    "            ## this is data of the form `arg_source` -> `argdown`\n",
    "            arg_src_argdown = {}\n",
    "            arg_src_argdown[\"id\"] = \"%s_%d_%s\" % (sname,k,\"arg_src_argdown\")\n",
    "            arg_src_argdown[\"question\"] = {}\n",
    "            arg_src_argdown[\"question\"][\"stem\"] = arg_source #<-- input field\n",
    "            arg_src_argdown[\"output\"] = argdown ##<-- left in newlines, not sure what the tokenizer will do here \n",
    "            arg_src_argdown[\"prefix\"] = \"gen:\" ##<-- model specific field, indicates the model mode\n",
    "            \n",
    "            write_file.write(json.dumps(arg_src_argdown))\n",
    "            write_file.write(\"\\n\")\n",
    "        \n",
    "            ## this part of the data as `argdown -> conclusion`\n",
    "            conclusion_pointers = []\n",
    "            for conclusion in conclusion_statements: \n",
    "                if conclusion[\"text\"] in argdown:\n",
    "                    conclusion_pointers.append(conclusion[\"ref_reco\"])\n",
    "            if conclusion_pointers: \n",
    "                clist = ','.join([str(v) for v in sorted(conclusion_pointers)])\n",
    "            \n",
    "                argdown_concl = {}\n",
    "                argdown_concl[\"id\"] = \"%s_%d_%s\" % (sname,k,\"argdown_concl\")\n",
    "                argdown_concl[\"question\"] = {}\n",
    "                argdown_concl[\"question\"][\"stem\"] = argdown ##<-- input \n",
    "                argdown_concl[\"output\"] = clist ##<-- output \n",
    "                argdown_concl[\"prefix\"] = \"answer:\" ##<-- important, indicates that we will measure accuracy\n",
    "                \n",
    "                write_file.write(json.dumps(argdown_concl))\n",
    "                write_file.write(\"\\n\")\n",
    "                \n",
    "                \n",
    "        write_file.close()\n",
    "        \n",
    "    ### write to wandb \n",
    "    artifact = wandb.Artifact(\"aaac_multi_angle\",type='dataset')\n",
    "    artifact.add_dir(tempdir)\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
