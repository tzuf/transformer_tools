{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../../')\n",
    "import wandb\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import tempfile\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_CACHE = str(pathlib.PosixPath('~/.wandb_cache').expanduser())\n",
    "VERSION     =\"v3\" ##<- update if you want to use a different verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = os.path.join(WANDB_CACHE,\"aaac_raw:%s\" % VERSION)\n",
    "def grab_raw_data(path):\n",
    "    if not os.path.isdir(FILE_PATH):\n",
    "        with wandb.init() as run: \n",
    "            artifact = run.use_artifact(\n",
    "                'aaac/aaac_model_runs/aaac_raw:%s' % VERSION, \n",
    "                type='dataset'\n",
    "            )\n",
    "            artifact_dir = artifact.download(root=FILE_PATH)\n",
    "grab_raw_data(FILE_PATH) \n",
    "DATA_JSON=os.path.join(FILE_PATH,\"aaac.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grabs the raw `aaac` corpus (with version `v0`) from wandb and places it into a wandb cache. It first requires having some global access to your `WANDB_API_KEY`, which can be set by doing `export WANDB_API_KEY=....` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = []\n",
    "with open(DATA_JSON) as my_data: \n",
    "    for line in my_data: \n",
    "        line      = line.strip()\n",
    "        json_line = json.loads(line)\n",
    "        LINES.append(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(LINES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'text': 'Every ingredient of Shower Gel is an ingredient of Pure Elegance or an ingredient of EYE COLOUR DUO EC26',\n",
       "  'starts_at': 0,\n",
       "  'ref_reco': 8},\n",
       " {'text': 'to be an ingredient of Vitamin E Body Wash or an ingredient of EYEBROW PENCIL EB02 is necessary for being an ingredient of Shower Gel',\n",
       "  'starts_at': 257,\n",
       "  'ref_reco': 6},\n",
       " {'text': 'each thing that is not an ingredient of Matifying Veil is neither an ingredient of Vitamin E Body Wash nor an ingredient of EYEBROW PENCIL EB02',\n",
       "  'starts_at': 396,\n",
       "  'ref_reco': 4},\n",
       " {'text': 'not being an ingredient of Tinker Bell Tattoo is sufficient for not being an ingredient of Matifying Veil',\n",
       "  'starts_at': 545,\n",
       "  'ref_reco': 1},\n",
       " {'text': 'being an ingredient of Tinker Bell Tattoo is sufficient for not being an ingredient of EYE COLOUR DUO EC26',\n",
       "  'starts_at': 656,\n",
       "  'ref_reco': 2},\n",
       " {'text': 'each thing that is not an ingredient of Matifying Veil is neither an ingredient of Vitamin E Body Wash nor an ingredient of EYEBROW PENCIL EB02',\n",
       "  'starts_at': 768,\n",
       "  'ref_reco': 4}]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "LINES[1][\"reason_statements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argument_source',\n",
       " 'argdown_reconstruction',\n",
       " 'reason_statements',\n",
       " 'conclusion_statements',\n",
       " 'explicit_premises',\n",
       " 'explicit_premises_formalized',\n",
       " 'implicit_premises',\n",
       " 'implicit_premises_formalized',\n",
       " 'conclusion',\n",
       " 'conclusion_formalized',\n",
       " 'intermediary_conclusions_formalized',\n",
       " 'intermediary_conclusions',\n",
       " 'id',\n",
       " 'predicate_placeholders',\n",
       " 'entity_placeholders',\n",
       " 'steps',\n",
       " 'n_premises',\n",
       " 'base_scheme_groups',\n",
       " 'scheme_variants',\n",
       " 'domain_id',\n",
       " 'domain_type',\n",
       " 'plcd_subs',\n",
       " 'argdown_index_map',\n",
       " 'presentation_parameters']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(LINES[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines how to present reason and conclusion statements to the model\n",
    "def format_statements_list(statements: list) -> str:\n",
    "    if len(statements)==0:\n",
    "        return \"None\"\n",
    "    list_as_string = [\"%s {ref: (%s)}\" % (sdict['text'],sdict['ref_reco']) for sdict in statements]\n",
    "    list_as_string = \" | \".join(list_as_string)\n",
    "    return list_as_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'being an ingredient of Pure Elegance is necessary for being an ingredient of Shower Gel {ref: (9)}'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "format_statements_list(LINES[1][\"conclusion_statements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# define modes in terms of keys\n",
    "modes = [\n",
    "    {'from':['argument_source'],'to':'argdown_reconstruction'},\n",
    "    {'from':['argument_source','reason_statements'],'to':'argdown_reconstruction'},\n",
    "    {'from':['argument_source','conclusion_statements'],'to':'argdown_reconstruction'},\n",
    "    {'from':['reason_statements','conclusion_statements'],'to':'argdown_reconstruction'},\n",
    "    {'from':['argument_source'],'to':'reason_statements'},\n",
    "    {'from':['argument_source','argdown_reconstruction'],'to':'reason_statements'},\n",
    "    {'from':['argument_source','conclusion_statements'],'to':'reason_statements'},\n",
    "    {'from':['argument_source'],'to':'conclusion_statements'},\n",
    "    {'from':['argument_source','argdown_reconstruction'],'to':'conclusion_statements'},\n",
    "    {'from':['argument_source','reason_statements'],'to':'conclusion_statements'},\n",
    "]\n",
    "len(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amount = int(len(LINES)*0.7)\n",
    "eval_amount  = int(len(LINES)*0.15)\n",
    "random.shuffle(LINES)\n",
    "train_instances = LINES[:train_amount]\n",
    "dev_instances   = LINES[train_amount:train_amount+eval_amount]\n",
    "test_instances  = LINES[train_amount+eval_amount:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just took a random train/test/dev split to start with. Not sure how much this makes sense given the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.29 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.12<br/>\n                Syncing run <strong style=\"color:#cdcd00\">dataset_upload</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/aaac/dataset_versions\" target=\"_blank\">https://wandb.ai/aaac/dataset_versions</a><br/>\n                Run page: <a href=\"https://wandb.ai/aaac/dataset_versions/runs/1fdmsoub\" target=\"_blank\">https://wandb.ai/aaac/dataset_versions/runs/1fdmsoub</a><br/>\n                Run data is saved locally in <code>/Users/ggbetz/git/transformer_tools/notebooks/wandb/run-20210504_124602-1fdmsoub</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/var/folders/ql/h_s52yl51x70ynttgg820gz80000gp/T/tmp1cjnzzaa)... Done. 0.2s\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 7261<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "253310522cc14119b6832363a0b78182"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>/Users/ggbetz/git/transformer_tools/notebooks/wandb/run-20210504_124602-1fdmsoub/logs/debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>/Users/ggbetz/git/transformer_tools/notebooks/wandb/run-20210504_124602-1fdmsoub/logs/debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">dataset_upload</strong>: <a href=\"https://wandb.ai/aaac/dataset_versions/runs/1fdmsoub\" target=\"_blank\">https://wandb.ai/aaac/dataset_versions/runs/1fdmsoub</a><br/>\n                "
     },
     "metadata": {}
    }
   ],
   "source": [
    "##open wandb again\n",
    "run = wandb.init(entity=\"aaac\",project=\"dataset_versions\",name=\"dataset_upload\")\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tempdir: \n",
    "    for sname,split in [\n",
    "        (\"train\",train_instances),\n",
    "        (\"dev\",dev_instances),\n",
    "        (\"test\",test_instances)\n",
    "    ]:\n",
    "        ### outputfile \n",
    "        over = 0\n",
    "        total = 0\n",
    "        \n",
    "        file_out = os.path.join(tempdir,sname+\".jsonl\")\n",
    "        write_file = open(file_out,'w')\n",
    "    \n",
    "        for k,instance in enumerate(split):\n",
    "            arg_source            = instance[\"argument_source\"]\n",
    "            conclusion_statements = instance[\"conclusion_statements\"]\n",
    "            reason_statements     = instance[\"reason_statements\"]\n",
    "            argdown               = instance[\"argdown_reconstruction\"]\n",
    " \n",
    "        \n",
    "            ### iterate over all modes\n",
    "            for mode in modes:\n",
    "                mname = \"+\".join(mode['from']) +'>'+mode['to']\n",
    "\n",
    "                # construct input\n",
    "                question=\"\"\n",
    "                for key_from in mode['from']:\n",
    "                    add = instance[key_from]\n",
    "                    if key_from in [\"reason_statements\",\"conclusion_statements\"]:\n",
    "                        add = format_statements_list(add)\n",
    "                    question = question + \" %s: %s\" % (key_from,add)\n",
    "                question = question + \" \" + mode['to'] +\":\"\n",
    "                question = question.strip()\n",
    "\n",
    "                ### arbitrary limitation on input size for now\n",
    "                ## transformer is limited here\n",
    "                if len(question.split()) >= 280: continue \n",
    "\n",
    "                # construct output\n",
    "                output=instance[mode['to']]\n",
    "                if mode['to'] in [\"reason_statements\",\"conclusion_statements\"]:\n",
    "                    output = format_statements_list(output)\n",
    "                output = output.strip()\n",
    "\n",
    "                ### arbitrary limitation on output size for now\n",
    "                if len(output.split()) >= 280: continue \n",
    "\n",
    "                # put input and output together\n",
    "                ### json line format and schema for Kyle's model \n",
    "                new_item = {}\n",
    "                new_item[\"id\"] = \"%s_%d_%s\" % (sname,k,mname)\n",
    "                new_item[\"question\"] = {}\n",
    "                new_item[\"question\"][\"stem\"] = question #<-- input field\n",
    "                new_item[\"output\"] = output ##<-- left in newlines, tokenizer will ignore them\n",
    "                new_item[\"prefix\"] = \"gen:\" ##<-- model specific field, indicates the model mode\n",
    "                write_file.write(json.dumps(new_item))\n",
    "                write_file.write(\"\\n\")\n",
    "                \n",
    "        write_file.close()\n",
    "        \n",
    "    ### write to wandb \n",
    "    artifact = wandb.Artifact(\"aaac_multi_angle\",type='dataset')\n",
    "    artifact.add_dir(tempdir)\n",
    "    run.log_artifact(artifact)\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python367jvsc74a57bd0318670b9451e2b0a97a0b451ec166eede77923c420a4d40971c604c0283690ce",
   "display_name": "Python 3.6.7 64-bit ('transformer_tools': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}